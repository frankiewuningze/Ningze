{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dirty-fleece",
   "metadata": {},
   "source": [
    "# Model 4 (Quelle aus Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "alpine-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crude-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_namespace(namespace):\n",
    "    def wrapper(f):\n",
    "        def wrapped_f(*args, **kwargs):\n",
    "            with tf.name_scope(namespace):\n",
    "                return f(*args, **kwargs)\n",
    "\n",
    "        return wrapped_f\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "prostate-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "\n",
    "    def __init__(self, input_shape, encode_sizes, latent_size, decode_sizes=None, mu_prior=None, sigma_prior=None,\n",
    "                 lr=10e-4,  momentum=0.9, save_model=True):\n",
    "        self.encode_sizes = encode_sizes\n",
    "        self.latent_size = latent_size\n",
    "        self.decode_sizes = decode_sizes or encode_sizes[::-1]\n",
    "        self.mu_prior = mu_prior or np.zeros([latent_size], dtype='float32')\n",
    "        self.sigma_prior = sigma_prior or np.ones([latent_size], 'float32')\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.input_shape = input_shape\n",
    "        self.save_model = save_model\n",
    "        self._build_graph(input_shape, latent_size)\n",
    "\n",
    "    def _build_graph(self, input_shape, latent_size):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self._create_placeholders(input_shape)\n",
    "            self._create_encoder(self.X)\n",
    "            self._create_latent_distribution(self.encoder, latent_size)\n",
    "            self._create_decoder(self.z)\n",
    "            self.loss = - self.elbo(self.X, self.decoder, self.mu, self.log_sigma_square, self.sigma_square,\n",
    "                                    tf.constant(self.mu_prior), tf.constant(self.sigma_prior))\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr, self.momentum)\n",
    "            self.opt_op = self.opt.minimize(self.loss)\n",
    "            self.session = tf.InteractiveSession(graph=self.graph)\n",
    "        writer = tf.summary.FileWriter(logdir='logdir', graph=self.graph)\n",
    "        writer.flush()\n",
    "\n",
    "    @property\n",
    "    def k_init(self):\n",
    "        return {'kernel_initializer': tf.glorot_uniform_initializer()}\n",
    "\n",
    "    def elbo(self, X_true, X_pred, mu, log_sigma, sigma, mu_prior, sigma_prior):\n",
    "        epsilon = tf.constant(0.000001)\n",
    "        self.mae = tf.losses.absolute_difference(X_true, X_pred, reduction=tf.losses.Reduction.NONE)\n",
    "        self.mae_sum = tf.reduce_sum(self.mae, axis=1)\n",
    "        log_sigma_prior = tf.log(sigma_prior + epsilon)\n",
    "        mu_diff = mu - mu_prior\n",
    "        self.kl = log_sigma_prior - log_sigma - 1 + (sigma + tf.multiply(mu_diff, mu_diff)) / sigma_prior\n",
    "        self.kl_sum = tf.reduce_sum(self.kl, axis=1)\n",
    "        return tf.reduce_mean(- self.mae_sum - self.kl_sum)\n",
    "\n",
    "    @tf_namespace('placeholders')\n",
    "    def _create_placeholders(self, input_shape):\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, *input_shape], name='X')\n",
    "\n",
    "    @tf_namespace('encoder')\n",
    "    def _create_encoder(self, X):\n",
    "        self.encode_layers = []\n",
    "        self.encoder = X\n",
    "        for i, conv_size in enumerate(self.encode_sizes):\n",
    "            self.encoder = tf.layers.dense(self.encoder, conv_size, **self.k_init,\n",
    "                                           activation=tf.nn.relu, name=f'encoder_{i + 1}')\n",
    "            self.encode_layers.append(self.encoder)\n",
    "            setattr(self, f'encoder_{i + 1}', self.encoder)\n",
    "\n",
    "    @tf_namespace('latent')\n",
    "    def _create_latent_distribution(self, encoder, latent_dim):\n",
    "        self.mu = tf.layers.dense(encoder, latent_dim, **self.k_init, name='mu')\n",
    "        self.log_sigma_square = tf.layers.dense(encoder, latent_dim,\n",
    "                                                **self.k_init, name='log_sigma_square')\n",
    "        self.sigma_square = tf.exp(self.log_sigma_square, 'sigma_square')\n",
    "        self.z = tf.add(self.mu, self.sigma_square * tf.random.normal(tf.shape(self.sigma_square)), 'z')\n",
    "\n",
    "    @tf_namespace('decoder')\n",
    "    def _create_decoder(self, z):\n",
    "        self.decoder = z\n",
    "        self.decode_layers = []\n",
    "        for i, lsize in enumerate(self.decode_sizes):\n",
    "            self.decoder = tf.layers.dense(self.decoder, lsize, **self.k_init,\n",
    "                                           activation=tf.nn.relu, name=f'decoder_{i + 1}')\n",
    "            setattr(self, f'decoder_{i + 1}', self.decoder)\n",
    "            self.decode_layers.append(self.decoder)\n",
    "            if i == len(self.decode_sizes) - 1:\n",
    "                self.mu_post = tf.layers.dense(self.decoder, self.input_shape[0], name='mu_posterior')\n",
    "                self.log_sigma_post = tf.layers.dense(self.decoder, self.input_shape[0])\n",
    "                self.sigma_post = tf.exp(self.log_sigma_post, 'sigma_square_posterior')\n",
    "                self.decoder = tf.add(self.mu_post,\n",
    "                                      self.sigma_post * tf.random.normal((self.input_shape[0],), name='eps_post'),\n",
    "                                      name='decoder_output')\n",
    "                setattr(self, f'decoder_{i + 2}', self.decoder)\n",
    "                self.decode_layers.append(self.decoder)\n",
    "        return self.decoder\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return [(f'encoder_{i}', getattr(self, f'encoder_{i}')) for i in range(1, len(self.encode_layers) + 1)] + \\\n",
    "               [('mu', self.mu), ('sigma', self.log_sigma_square), ('z', self.z)] + \\\n",
    "               [(f'decoder_{i}', getattr(self, f'decoder_{i}')) for i in range(1, len(self.decode_layers) + 1)]\n",
    "\n",
    "    def fit(self, X, epochs, batch_size, print_every=50, save_every_epochs=5, verbose=True):\n",
    "        n_batch = ceil(X.shape[0] / batch_size)\n",
    "        if self.save_model:\n",
    "            saver = tf.train.Saver()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            np.random.shuffle(X)\n",
    "            acc_loss = 0\n",
    "            counter = 0\n",
    "            for i in range(n_batch):\n",
    "                slice_batch = slice(i * batch_size, (i + 1) * batch_size) if i != n_batch - 1 else slice(\n",
    "                    i * batch_size,\n",
    "                    None)\n",
    "                X_batch = X[slice_batch, :]\n",
    "                batch_loss, _ = self.session.run([self.loss, self.opt_op], {self.X: X_batch})\n",
    "                acc_loss += batch_loss\n",
    "                if verbose and counter % print_every == 0:\n",
    "                    print(f\" Epoch {epoch} - batch {i} - neg_ELBO = {batch_loss}\")\n",
    "                counter += 1\n",
    "            if verbose:\n",
    "                print(f'\\nEpoch {epoch} - Avg loss = {acc_loss / n_batch}')\n",
    "                print('\\n' + ('-' * 70))\n",
    "            if self.save_model and (epoch+1) % save_every_epochs == 0:\n",
    "                saver.save(self.session, \"ckpts/ad_vae.ckpt\")\n",
    "\n",
    "    def generate(self, n=1, mu_prior=None, sigma_prior=None):\n",
    "        \"\"\"\n",
    "        Generate new examples sampling from the latent distribution\n",
    "        :param n: number of examples to generate\n",
    "        :param mu_prior:\n",
    "        :param sigma_prior:\n",
    "        :return: a matrix of size [n, p] where p is the number of variables of X_train\n",
    "        \"\"\"\n",
    "        if mu_prior is None:\n",
    "            mu_prior = self.mu_prior\n",
    "        if sigma_prior is None:\n",
    "            sigma_prior = self.sigma_prior\n",
    "        z = np.random.multivariate_normal(mu_prior, np.diag(sigma_prior), [n])\n",
    "        return self.session.run(self.decoder, feed_dict={self.z: z})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.session.run(self.decoder, feed_dict={self.X: X})\n",
    "\n",
    "    def reconstructed_probability(self, X, L=100):\n",
    "        reconstructed_prob = np.zeros((X.shape[0],), dtype='float32')\n",
    "        mu_hat, sigma_hat = self.session.run([self.mu_post, self.sigma_post], {self.X: X})\n",
    "        for l in range(L):\n",
    "            mu_hat = mu_hat.reshape(X.shape)\n",
    "            sigma_hat = sigma_hat.reshape(X.shape) + 0.00001\n",
    "            for i in range(X.shape[0]):\n",
    "                p_l = multivariate_normal.pdf(X[i, :], mu_hat[i, :], np.diag(sigma_hat[i, :]))\n",
    "                reconstructed_prob[i] += p_l\n",
    "        reconstructed_prob /= L\n",
    "        return reconstructed_prob\n",
    "\n",
    "    def is_outlier(self, X, L=100, alpha=0.05):\n",
    "        p_hat = self.reconstructed_probability(X, L)\n",
    "        return p_hat < alpha\n",
    "\n",
    "    def open(self):\n",
    "        if not hasattr(self, 'session') or self.session is None:\n",
    "            if self.graph is None:\n",
    "                self._build_graph(self.input_shape, self.latent_size)\n",
    "            else:\n",
    "                self.session = tf.InteractiveSession(graph=self.graph)\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(VAE, 'session') and VAE.session is not None:\n",
    "            VAE.session.close()\n",
    "            VAE.session = None\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n",
    "\n",
    "    def __delete__(self, instance):\n",
    "        self.close()\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        if key == 'session':\n",
    "            if hasattr(self, 'session') and self.session is not None:\n",
    "                self.close()\n",
    "            VAE.session = value\n",
    "        else:\n",
    "            self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        if item == 'session':\n",
    "            self.close()\n",
    "            del VAE.__dict__['session']\n",
    "        else:\n",
    "            del self.__dict__[item]\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.open()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-fellowship",
   "metadata": {},
   "source": [
    "# Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "given-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "import h5py\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "static-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_LIB = r\"E:\\ningze\\process_analysis\"\n",
    "sys.path.append(PATH_LIB)\n",
    "import process_analysis as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crazy-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "roman-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_analysis.io.live_hdf import File as HdfFile\n",
    "from process_analysis.io.live_hdf import Group as HdfGroup\n",
    "from process_analysis.io.live_hdf import Dataset as HdfDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceramic-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"E:/ningze/data.h5\"\n",
    "KEY_CONST = '3_time_series/0/constants'\n",
    "KEY_TS = '3_time_series/0/time_series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wireless-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = HdfFile(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "universal-serbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>segment</th>\n",
       "      <th>TSp_ActSpeed</th>\n",
       "      <th>notch</th>\n",
       "      <th>io_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2386.593105</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2386.593497</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2386.587616</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2386.595233</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2386.601852</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            experiment  segment  TSp_ActSpeed  notch  io_label\n",
       "segment_id                                                    \n",
       "0                    0        0   2386.593105      0      True\n",
       "1                    0        1   2386.593497      0      True\n",
       "2                    0        2   2386.587616      0      True\n",
       "3                    0        3   2386.595233      0      True\n",
       "4                    0        4   2386.601852      0      True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_const = f[KEY_CONST].value.set_index('index')\n",
    "df_const.index.name = 'segment_id'\n",
    "df_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-times",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>segment</th>\n",
       "      <th>TSp_ActSpeed</th>\n",
       "      <th>notch</th>\n",
       "      <th>io_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2983.518300</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2983.505328</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2983.506711</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2983.510880</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2983.508447</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2983.512393</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2983.506904</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2983.518411</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2983.518000</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2983.517200</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>2983.517297</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2983.515809</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2983.509150</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>2983.524322</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2983.514811</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2983.515983</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2983.510299</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>2983.512161</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2983.511003</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2983.505324</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>2983.520481</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2983.516435</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>2983.518051</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>2983.514246</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2983.514209</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2983.516910</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2983.520300</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2983.512300</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>2983.514797</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>2983.508005</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2983.512393</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>2983.508223</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2983.511343</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>2983.525712</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>2983.509720</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2983.509382</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            experiment  segment  TSp_ActSpeed  notch  io_label\n",
       "segment_id                                                    \n",
       "126                  1       36   2983.518300      6     False\n",
       "127                  1       37   2983.505328      6     False\n",
       "128                  1       38   2983.506711      6     False\n",
       "129                  1       39   2983.510880      6     False\n",
       "130                  1       40   2983.508447      6     False\n",
       "131                  1       41   2983.512393      6     False\n",
       "132                  1       42   2983.506904      7     False\n",
       "133                  1       43   2983.518411      7     False\n",
       "134                  1       44   2983.518000      7     False\n",
       "135                  1       45   2983.517200      7     False\n",
       "136                  1       46   2983.517297      7     False\n",
       "137                  1       47   2983.515809      7     False\n",
       "138                  1       48   2983.509150      8     False\n",
       "139                  1       49   2983.524322      8     False\n",
       "140                  1       50   2983.514811      8     False\n",
       "141                  1       51   2983.515983      8     False\n",
       "142                  1       52   2983.510299      8     False\n",
       "143                  1       53   2983.512161      8     False\n",
       "216                  2       36   2983.511003      6     False\n",
       "217                  2       37   2983.505324      6     False\n",
       "218                  2       38   2983.520481      6     False\n",
       "219                  2       39   2983.516435      6     False\n",
       "220                  2       40   2983.518051      6     False\n",
       "221                  2       41   2983.514246      6     False\n",
       "222                  2       42   2983.514209      7     False\n",
       "223                  2       43   2983.516910      7     False\n",
       "224                  2       44   2983.520300      7     False\n",
       "225                  2       45   2983.512300      7     False\n",
       "226                  2       46   2983.514797      7     False\n",
       "227                  2       47   2983.508005      7     False\n",
       "228                  2       48   2983.512393      8     False\n",
       "229                  2       49   2983.508223      8     False\n",
       "230                  2       50   2983.511343      8     False\n",
       "231                  2       51   2983.525712      8     False\n",
       "232                  2       52   2983.509720      8     False\n",
       "233                  2       53   2983.509382      8     False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_const[df_const['io_label']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "challenging-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dict()\n",
    "for e in f[KEY_TS]:\n",
    "    if isinstance(e,HdfDataset):\n",
    "        dfs[int(e.name)]=e.value.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "outdoor-viking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf5b03ff4aa44bab14d805b91de5121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b804746808b14961b1b02b95f90f0168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Experiment'), IntSlider(value=0, max=2))), VBox(children=(Label(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def mk_plot(val):  \n",
    "    seg_id = df_const[(df_const['experiment']==sli_exp.value) & (df_const['segment']==sli_seg.value)].iloc[0].name\n",
    "    \n",
    "    lbl.value=str(df_const.loc[seg_id]['io_label'])\n",
    "    \n",
    "    \n",
    "    ax.clear()\n",
    "    ax.plot(dfs[seg_id]['curr_norm'])\n",
    "    \n",
    "#Controls:\n",
    "lbl = widgets.Label('Empty')\n",
    "sli_exp = widgets.IntSlider(min=min(df_const['experiment']),max=max(df_const['experiment']))\n",
    "sli_exp.observe(mk_plot,'value')\n",
    "\n",
    "sli_seg = widgets.IntSlider(min=min(df_const['segment']),max=max(df_const['segment']))\n",
    "sli_seg.observe(mk_plot,'value')\n",
    "io = widgets.HBox([widgets.VBox([widgets.Label('Experiment'),sli_exp]),widgets.VBox([widgets.Label('Segment'),sli_seg]),widgets.VBox([widgets.Label('io_label'),lbl])])\n",
    "\n",
    "mk_plot(None)\n",
    "io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_good = []\n",
    "data_y_good = []\n",
    "data_x_bad = []\n",
    "data_y_bad = []\n",
    "\n",
    "for i,k in enumerate(dfs.keys()):\n",
    "    data = pa.resample(dfs[k]['curr_norm'],0.1) #Jonas: Neues Notebook: curr_norm\n",
    "    \n",
    "    if df_const['io_label'].loc[k] == True:\n",
    "        data_x_good.append(data)\n",
    "        data_y_good.append(df_const['io_label'].loc[k])\n",
    "    else:\n",
    "        data_x_bad.append(data)\n",
    "        data_y_bad.append(df_const['io_label'].loc[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "protected-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_X = data_x_good[:200]\n",
    "TRAIN_Y = data_y_good[:200]\n",
    "\n",
    "VALID_X = data_x_good[180:200]\n",
    "VALID_Y = data_y_good[180:200]\n",
    "\n",
    "TEST_X = data_x_good[200:]+data_x_bad\n",
    "TEST_Y = data_y_good[200:]+data_y_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wireless-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e33f62f43a4d64a529d0f918019a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74df553d90a4d1b84950546e09fd47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, max=200), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def on_change(value):\n",
    "    ax.clear()\n",
    "    ax.plot(TRAIN_X[value.new])\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(TRAIN_Y[value.new])\n",
    "    \n",
    "\n",
    "slider = widgets.IntSlider(min=0,max=len(TRAIN_X))\n",
    "slider.observe(on_change,'value')\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "widgets.HBox([slider,out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prime-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "def Resampling_length(x:list):\n",
    "    \n",
    "    neu_list=[]\n",
    "    \n",
    "    maxlen=len(max(x,key=len))\n",
    "    \n",
    "    maxlen=166\n",
    "    \n",
    "    for i in range (len(x)) :\n",
    "        je_len=len(x[i])\n",
    "        factor=round(je_len/maxlen/10,3)\n",
    "        \n",
    "        if je_len<maxlen:\n",
    "            re_array=pa.resample(x[i],factor)\n",
    "            neu_list.append(re_array)\n",
    "       \n",
    "        else:\n",
    "            neu_list.append(x[i])\n",
    "    \n",
    "    neu_list=keras.preprocessing.sequence.pad_sequences(neu_list, maxlen=maxlen, dtype='float32', padding='pre', truncating='pre', value=0.0)\n",
    "    #print(type(neu_list))\n",
    "    return neu_list              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "military-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_X_neu=Resampling_length(TRAIN_X)\n",
    "\n",
    "\n",
    "VALID_X_neu=Resampling_length(VALID_X)\n",
    "\n",
    "\n",
    "TEST_X_neu=Resampling_length(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intellectual-reading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6af377bab44f21a739a1744b1815a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2e1f46ace14cf7bc89ad81a4431ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, max=20), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def on_change(value):\n",
    "    ax.clear()\n",
    "    ax.plot(VALID_X_neu[value.new])\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(VALID_Y[value.new])\n",
    "    \n",
    "\n",
    "slider = widgets.IntSlider(min=0,max=len(VALID_X_neu))\n",
    "slider.observe(on_change,'value')\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "widgets.HBox([slider,out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "becoming-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_X=pd.DataFrame(TRAIN_X_neu)  #Dataframe entfalten\n",
    "TEST_X=pd.DataFrame(TEST_X_neu)\n",
    "VALID_X=pd.DataFrame(VALID_X_neu)\n",
    "# TRAIN_X.fillna(0,inplace = True) #NaN Fill\n",
    "VALID_X.fillna(0,inplace=True)\n",
    "TEST_X.fillna(0,inplace=True)\n",
    "TRAIN_X=np.array(TRAIN_X,dtype=\"object\")\n",
    "TEST_X=np.array(TEST_X,dtype=\"object\")\n",
    "VALID_X=np.array(VALID_X,dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "recognized-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 166)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid=pd.DataFrame(VALID_X)\n",
    "data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expensive-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer=Normalizer(norm='l2')\n",
    "\n",
    "data_train=normalizer.transform(TRAIN_X)\n",
    "data_valid=normalizer.transform(data_valid)\n",
    "data_test=normalizer.transform(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "terminal-liberty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d5ec2bc2fe4eab983003e5639d44a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385cbb8205dc4c3abd642880419ea79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, max=200), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def on_change(value):\n",
    "    ax.clear()\n",
    "    ax.plot(data_train[value.new])\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(TRAIN_Y[value.new])\n",
    "    \n",
    "\n",
    "slider = widgets.IntSlider(min=0,max=len(data_train))\n",
    "slider.observe(on_change,'value')\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "widgets.HBox([slider,out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "capable-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "joined-surface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 166)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-bullet",
   "metadata": {},
   "source": [
    "# Parameter erstellen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "green-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bright-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ningz\\anaconda3\\envs\\tf_2.3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "latent_size = 16\n",
    "encoders_sizes = np.linspace(latent_size, data_train.shape[1], 64).astype('int')\n",
    "vae = VAE((data_train.shape[1],), encode_sizes=encoders_sizes, latent_size=latent_size, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "confidential-cooler",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ningz\\anaconda3\\envs\\tf_2.3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 - batch 0 - neg_ELBO = 136.18426513671875\n",
      " Epoch 1 - batch 50 - neg_ELBO = 107.23762512207031\n",
      " Epoch 1 - batch 100 - neg_ELBO = 74.89546203613281\n",
      " Epoch 1 - batch 150 - neg_ELBO = 14.104019165039062\n",
      "\n",
      "Epoch 1 - Avg loss = 69.95962010622024\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 2 - batch 0 - neg_ELBO = 4.3364715576171875\n",
      " Epoch 2 - batch 50 - neg_ELBO = 4.104082107543945\n",
      " Epoch 2 - batch 100 - neg_ELBO = 3.3016879558563232\n",
      " Epoch 2 - batch 150 - neg_ELBO = 2.953464984893799\n",
      "\n",
      "Epoch 2 - Avg loss = 3.266316763162613\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 3 - batch 0 - neg_ELBO = 2.9889235496520996\n",
      " Epoch 3 - batch 50 - neg_ELBO = 2.8736207485198975\n",
      " Epoch 3 - batch 100 - neg_ELBO = 2.3951451778411865\n",
      " Epoch 3 - batch 150 - neg_ELBO = 2.3085007667541504\n",
      "\n",
      "Epoch 3 - Avg loss = 2.420292662382126\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 4 - batch 0 - neg_ELBO = 2.1771483421325684\n",
      " Epoch 4 - batch 50 - neg_ELBO = 2.224940776824951\n",
      " Epoch 4 - batch 100 - neg_ELBO = 2.2602877616882324\n",
      " Epoch 4 - batch 150 - neg_ELBO = 1.7961208820343018\n",
      "\n",
      "Epoch 4 - Avg loss = 2.0947857719659804\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 5 - batch 0 - neg_ELBO = 2.1021335124969482\n",
      " Epoch 5 - batch 50 - neg_ELBO = 2.1546175479888916\n",
      " Epoch 5 - batch 100 - neg_ELBO = 1.8437879085540771\n",
      " Epoch 5 - batch 150 - neg_ELBO = 2.127805709838867\n",
      "\n",
      "Epoch 5 - Avg loss = 1.9342863196134568\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 6 - batch 0 - neg_ELBO = 1.7855896949768066\n",
      " Epoch 6 - batch 50 - neg_ELBO = 1.8240654468536377\n",
      " Epoch 6 - batch 100 - neg_ELBO = 1.636472463607788\n",
      " Epoch 6 - batch 150 - neg_ELBO = 1.914107084274292\n",
      "\n",
      "Epoch 6 - Avg loss = 1.7494639486074448\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 7 - batch 0 - neg_ELBO = 1.655802845954895\n",
      " Epoch 7 - batch 50 - neg_ELBO = 1.757839322090149\n",
      " Epoch 7 - batch 100 - neg_ELBO = 1.751192331314087\n",
      " Epoch 7 - batch 150 - neg_ELBO = 1.7746366262435913\n",
      "\n",
      "Epoch 7 - Avg loss = 1.7495725947618483\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 8 - batch 0 - neg_ELBO = 1.928817868232727\n",
      " Epoch 8 - batch 50 - neg_ELBO = 1.564424991607666\n",
      " Epoch 8 - batch 100 - neg_ELBO = 1.7425458431243896\n",
      " Epoch 8 - batch 150 - neg_ELBO = 1.94809889793396\n",
      "\n",
      "Epoch 8 - Avg loss = 1.687777094244957\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 9 - batch 0 - neg_ELBO = 1.5605278015136719\n",
      " Epoch 9 - batch 50 - neg_ELBO = 1.5471237897872925\n",
      " Epoch 9 - batch 100 - neg_ELBO = 1.4779033660888672\n",
      " Epoch 9 - batch 150 - neg_ELBO = 1.3976280689239502\n",
      "\n",
      "Epoch 9 - Avg loss = 1.5507275193929673\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 10 - batch 0 - neg_ELBO = 1.6520532369613647\n",
      " Epoch 10 - batch 50 - neg_ELBO = 1.2916526794433594\n",
      " Epoch 10 - batch 100 - neg_ELBO = 1.3970322608947754\n",
      " Epoch 10 - batch 150 - neg_ELBO = 1.3510254621505737\n",
      "\n",
      "Epoch 10 - Avg loss = 1.5223939037322998\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 11 - batch 0 - neg_ELBO = 1.3677775859832764\n",
      " Epoch 11 - batch 50 - neg_ELBO = 1.4332091808319092\n",
      " Epoch 11 - batch 100 - neg_ELBO = 1.5132018327713013\n",
      " Epoch 11 - batch 150 - neg_ELBO = 1.332465648651123\n",
      "\n",
      "Epoch 11 - Avg loss = 1.4303979498147965\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 12 - batch 0 - neg_ELBO = 1.320929765701294\n",
      " Epoch 12 - batch 50 - neg_ELBO = 1.444553017616272\n",
      " Epoch 12 - batch 100 - neg_ELBO = 1.516823649406433\n",
      " Epoch 12 - batch 150 - neg_ELBO = 1.3932249546051025\n",
      "\n",
      "Epoch 12 - Avg loss = 1.401760641336441\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 13 - batch 0 - neg_ELBO = 1.5660221576690674\n",
      " Epoch 13 - batch 50 - neg_ELBO = 1.266517162322998\n",
      " Epoch 13 - batch 100 - neg_ELBO = 1.3442610502243042\n",
      " Epoch 13 - batch 150 - neg_ELBO = 1.311606764793396\n",
      "\n",
      "Epoch 13 - Avg loss = 1.345152462720871\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 14 - batch 0 - neg_ELBO = 1.575447678565979\n",
      " Epoch 14 - batch 50 - neg_ELBO = 1.2986485958099365\n",
      " Epoch 14 - batch 100 - neg_ELBO = 1.2832742929458618\n",
      " Epoch 14 - batch 150 - neg_ELBO = 1.1675102710723877\n",
      "\n",
      "Epoch 14 - Avg loss = 1.327482700943947\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 15 - batch 0 - neg_ELBO = 1.4046369791030884\n",
      " Epoch 15 - batch 50 - neg_ELBO = 1.1601170301437378\n",
      " Epoch 15 - batch 100 - neg_ELBO = 1.2125499248504639\n",
      " Epoch 15 - batch 150 - neg_ELBO = 1.1839208602905273\n",
      "\n",
      "Epoch 15 - Avg loss = 1.3008160263299942\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 16 - batch 0 - neg_ELBO = 1.2301454544067383\n",
      " Epoch 16 - batch 50 - neg_ELBO = 1.1876866817474365\n",
      " Epoch 16 - batch 100 - neg_ELBO = 1.0271258354187012\n",
      " Epoch 16 - batch 150 - neg_ELBO = 1.4600191116333008\n",
      "\n",
      "Epoch 16 - Avg loss = 1.249164046049118\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 17 - batch 0 - neg_ELBO = 1.138659954071045\n",
      " Epoch 17 - batch 50 - neg_ELBO = 1.2863070964813232\n",
      " Epoch 17 - batch 100 - neg_ELBO = 1.1676499843597412\n",
      " Epoch 17 - batch 150 - neg_ELBO = 1.1535574197769165\n",
      "\n",
      "Epoch 17 - Avg loss = 1.2557372453808784\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 18 - batch 0 - neg_ELBO = 1.2195039987564087\n",
      " Epoch 18 - batch 50 - neg_ELBO = 1.388319730758667\n",
      " Epoch 18 - batch 100 - neg_ELBO = 1.4779317378997803\n",
      " Epoch 18 - batch 150 - neg_ELBO = 1.1545822620391846\n",
      "\n",
      "Epoch 18 - Avg loss = 1.1936279791593551\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 19 - batch 0 - neg_ELBO = 1.1681230068206787\n",
      " Epoch 19 - batch 50 - neg_ELBO = 1.1690802574157715\n",
      " Epoch 19 - batch 100 - neg_ELBO = 1.1433833837509155\n",
      " Epoch 19 - batch 150 - neg_ELBO = 1.699988603591919\n",
      "\n",
      "Epoch 19 - Avg loss = 1.1819257089495658\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 20 - batch 0 - neg_ELBO = 1.1139932870864868\n",
      " Epoch 20 - batch 50 - neg_ELBO = 1.1553051471710205\n",
      " Epoch 20 - batch 100 - neg_ELBO = 1.1108325719833374\n",
      " Epoch 20 - batch 150 - neg_ELBO = 1.0602904558181763\n",
      "\n",
      "Epoch 20 - Avg loss = 1.1327482998371123\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 21 - batch 0 - neg_ELBO = 1.077165961265564\n",
      " Epoch 21 - batch 50 - neg_ELBO = 1.5294805765151978\n",
      " Epoch 21 - batch 100 - neg_ELBO = 1.0684494972229004\n",
      " Epoch 21 - batch 150 - neg_ELBO = 1.0984103679656982\n",
      "\n",
      "Epoch 21 - Avg loss = 1.1267685121297837\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 22 - batch 0 - neg_ELBO = 1.2511563301086426\n",
      " Epoch 22 - batch 50 - neg_ELBO = 1.0589338541030884\n",
      " Epoch 22 - batch 100 - neg_ELBO = 1.2310090065002441\n",
      " Epoch 22 - batch 150 - neg_ELBO = 0.8693456649780273\n",
      "\n",
      "Epoch 22 - Avg loss = 1.1204154509305955\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 23 - batch 0 - neg_ELBO = 0.9890615344047546\n",
      " Epoch 23 - batch 50 - neg_ELBO = 1.3656229972839355\n",
      " Epoch 23 - batch 100 - neg_ELBO = 1.286219835281372\n",
      " Epoch 23 - batch 150 - neg_ELBO = 1.0785378217697144\n",
      "\n",
      "Epoch 23 - Avg loss = 1.0948925578594209\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 24 - batch 0 - neg_ELBO = 0.9639666676521301\n",
      " Epoch 24 - batch 50 - neg_ELBO = 1.0461957454681396\n",
      " Epoch 24 - batch 100 - neg_ELBO = 0.8739821314811707\n",
      " Epoch 24 - batch 150 - neg_ELBO = 0.891815185546875\n",
      "\n",
      "Epoch 24 - Avg loss = 1.0564624983072282\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 25 - batch 0 - neg_ELBO = 1.0315532684326172\n",
      " Epoch 25 - batch 50 - neg_ELBO = 1.2825908660888672\n",
      " Epoch 25 - batch 100 - neg_ELBO = 1.0843322277069092\n",
      " Epoch 25 - batch 150 - neg_ELBO = 1.1419026851654053\n",
      "\n",
      "Epoch 25 - Avg loss = 1.0449364602565765\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 26 - batch 0 - neg_ELBO = 1.016956090927124\n",
      " Epoch 26 - batch 50 - neg_ELBO = 1.0100681781768799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 - batch 100 - neg_ELBO = 1.5238009691238403\n",
      " Epoch 26 - batch 150 - neg_ELBO = 1.1002066135406494\n",
      "\n",
      "Epoch 26 - Avg loss = 1.0322312223911285\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 27 - batch 0 - neg_ELBO = 1.2031705379486084\n",
      " Epoch 27 - batch 50 - neg_ELBO = 1.494158387184143\n",
      " Epoch 27 - batch 100 - neg_ELBO = 1.1084623336791992\n",
      " Epoch 27 - batch 150 - neg_ELBO = 0.9042102694511414\n",
      "\n",
      "Epoch 27 - Avg loss = 1.016342033445835\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 28 - batch 0 - neg_ELBO = 0.8246552348136902\n",
      " Epoch 28 - batch 50 - neg_ELBO = 0.8920706510543823\n",
      " Epoch 28 - batch 100 - neg_ELBO = 1.5128121376037598\n",
      " Epoch 28 - batch 150 - neg_ELBO = 0.8926951289176941\n",
      "\n",
      "Epoch 28 - Avg loss = 1.008898805975914\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 29 - batch 0 - neg_ELBO = 0.9851495027542114\n",
      " Epoch 29 - batch 50 - neg_ELBO = 0.9261157512664795\n",
      " Epoch 29 - batch 100 - neg_ELBO = 0.9081103205680847\n",
      " Epoch 29 - batch 150 - neg_ELBO = 0.8597549796104431\n",
      "\n",
      "Epoch 29 - Avg loss = 1.022439222931862\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 30 - batch 0 - neg_ELBO = 0.8465847969055176\n",
      " Epoch 30 - batch 50 - neg_ELBO = 0.9441060423851013\n",
      " Epoch 30 - batch 100 - neg_ELBO = 1.0687339305877686\n",
      " Epoch 30 - batch 150 - neg_ELBO = 1.049036979675293\n",
      "\n",
      "Epoch 30 - Avg loss = 0.9907966557145119\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 31 - batch 0 - neg_ELBO = 0.8586352467536926\n",
      " Epoch 31 - batch 50 - neg_ELBO = 0.8661603331565857\n",
      " Epoch 31 - batch 100 - neg_ELBO = 1.101497769355774\n",
      " Epoch 31 - batch 150 - neg_ELBO = 0.8531118631362915\n",
      "\n",
      "Epoch 31 - Avg loss = 0.9512399479746818\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 32 - batch 0 - neg_ELBO = 0.9667237401008606\n",
      " Epoch 32 - batch 50 - neg_ELBO = 0.891873836517334\n",
      " Epoch 32 - batch 100 - neg_ELBO = 0.9689149856567383\n",
      " Epoch 32 - batch 150 - neg_ELBO = 0.938093364238739\n",
      "\n",
      "Epoch 32 - Avg loss = 0.9308844131231307\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 33 - batch 0 - neg_ELBO = 0.8005327582359314\n",
      " Epoch 33 - batch 50 - neg_ELBO = 0.8822281360626221\n",
      " Epoch 33 - batch 100 - neg_ELBO = 0.790631115436554\n",
      " Epoch 33 - batch 150 - neg_ELBO = 0.8590749502182007\n",
      "\n",
      "Epoch 33 - Avg loss = 0.9397686994075776\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 34 - batch 0 - neg_ELBO = 0.836889922618866\n",
      " Epoch 34 - batch 50 - neg_ELBO = 1.0665385723114014\n",
      " Epoch 34 - batch 100 - neg_ELBO = 1.3998208045959473\n",
      " Epoch 34 - batch 150 - neg_ELBO = 0.8509874939918518\n",
      "\n",
      "Epoch 34 - Avg loss = 0.9393253955245018\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 35 - batch 0 - neg_ELBO = 0.8085541725158691\n",
      " Epoch 35 - batch 50 - neg_ELBO = 1.4008889198303223\n",
      " Epoch 35 - batch 100 - neg_ELBO = 0.860558271408081\n",
      " Epoch 35 - batch 150 - neg_ELBO = 0.793895423412323\n",
      "\n",
      "Epoch 35 - Avg loss = 0.9088272133469582\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 36 - batch 0 - neg_ELBO = 0.8256629109382629\n",
      " Epoch 36 - batch 50 - neg_ELBO = 0.8870459794998169\n",
      " Epoch 36 - batch 100 - neg_ELBO = 0.875932514667511\n",
      " Epoch 36 - batch 150 - neg_ELBO = 0.6806229948997498\n",
      "\n",
      "Epoch 36 - Avg loss = 0.8822035217285156\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 37 - batch 0 - neg_ELBO = 0.7353408336639404\n",
      " Epoch 37 - batch 50 - neg_ELBO = 0.8393816351890564\n",
      " Epoch 37 - batch 100 - neg_ELBO = 0.9210732579231262\n",
      " Epoch 37 - batch 150 - neg_ELBO = 1.3496196269989014\n",
      "\n",
      "Epoch 37 - Avg loss = 0.8934307089447975\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 38 - batch 0 - neg_ELBO = 0.9476062059402466\n",
      " Epoch 38 - batch 50 - neg_ELBO = 0.8092384338378906\n",
      " Epoch 38 - batch 100 - neg_ELBO = 0.8818665742874146\n",
      " Epoch 38 - batch 150 - neg_ELBO = 1.1905772686004639\n",
      "\n",
      "Epoch 38 - Avg loss = 0.8739823666214943\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 39 - batch 0 - neg_ELBO = 0.7541713118553162\n",
      " Epoch 39 - batch 50 - neg_ELBO = 0.898260235786438\n",
      " Epoch 39 - batch 100 - neg_ELBO = 1.043951392173767\n",
      " Epoch 39 - batch 150 - neg_ELBO = 0.752556324005127\n",
      "\n",
      "Epoch 39 - Avg loss = 0.8784822058677674\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 40 - batch 0 - neg_ELBO = 0.9863506555557251\n",
      " Epoch 40 - batch 50 - neg_ELBO = 0.9272253513336182\n",
      " Epoch 40 - batch 100 - neg_ELBO = 0.7535488605499268\n",
      " Epoch 40 - batch 150 - neg_ELBO = 0.825605034828186\n",
      "\n",
      "Epoch 40 - Avg loss = 0.8843852844834328\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 41 - batch 0 - neg_ELBO = 0.8534753322601318\n",
      " Epoch 41 - batch 50 - neg_ELBO = 0.8130022287368774\n",
      " Epoch 41 - batch 100 - neg_ELBO = 0.9484949111938477\n",
      " Epoch 41 - batch 150 - neg_ELBO = 0.7946837544441223\n",
      "\n",
      "Epoch 41 - Avg loss = 0.8634296545386314\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 42 - batch 0 - neg_ELBO = 0.995773434638977\n",
      " Epoch 42 - batch 50 - neg_ELBO = 0.6714515089988708\n",
      " Epoch 42 - batch 100 - neg_ELBO = 0.7904528975486755\n",
      " Epoch 42 - batch 150 - neg_ELBO = 0.7999130487442017\n",
      "\n",
      "Epoch 42 - Avg loss = 0.8461142891645431\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 43 - batch 0 - neg_ELBO = 0.7983378171920776\n",
      " Epoch 43 - batch 50 - neg_ELBO = 1.0841357707977295\n",
      " Epoch 43 - batch 100 - neg_ELBO = 0.6855648756027222\n",
      " Epoch 43 - batch 150 - neg_ELBO = 0.8220439553260803\n",
      "\n",
      "Epoch 43 - Avg loss = 0.8187694489955902\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 44 - batch 0 - neg_ELBO = 0.8208295106887817\n",
      " Epoch 44 - batch 50 - neg_ELBO = 1.4305890798568726\n",
      " Epoch 44 - batch 100 - neg_ELBO = 0.7062987685203552\n",
      " Epoch 44 - batch 150 - neg_ELBO = 0.702657163143158\n",
      "\n",
      "Epoch 44 - Avg loss = 0.8526843246817589\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 45 - batch 0 - neg_ELBO = 0.7229891419410706\n",
      " Epoch 45 - batch 50 - neg_ELBO = 0.6939763426780701\n",
      " Epoch 45 - batch 100 - neg_ELBO = 0.7017890214920044\n",
      " Epoch 45 - batch 150 - neg_ELBO = 0.7049075365066528\n",
      "\n",
      "Epoch 45 - Avg loss = 0.8163532331585884\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 46 - batch 0 - neg_ELBO = 0.8431901335716248\n",
      " Epoch 46 - batch 50 - neg_ELBO = 0.6240189671516418\n",
      " Epoch 46 - batch 100 - neg_ELBO = 0.8657554388046265\n",
      " Epoch 46 - batch 150 - neg_ELBO = 0.8261587023735046\n",
      "\n",
      "Epoch 46 - Avg loss = 0.8280916464328766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 47 - batch 0 - neg_ELBO = 0.7012563943862915\n",
      " Epoch 47 - batch 50 - neg_ELBO = 0.8613058924674988\n",
      " Epoch 47 - batch 100 - neg_ELBO = 0.6788675785064697\n",
      " Epoch 47 - batch 150 - neg_ELBO = 0.8240202069282532\n",
      "\n",
      "Epoch 47 - Avg loss = 0.8084509035944939\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 48 - batch 0 - neg_ELBO = 0.6486253142356873\n",
      " Epoch 48 - batch 50 - neg_ELBO = 0.7527457475662231\n",
      " Epoch 48 - batch 100 - neg_ELBO = 0.809151291847229\n",
      " Epoch 48 - batch 150 - neg_ELBO = 0.6406211256980896\n",
      "\n",
      "Epoch 48 - Avg loss = 0.79365642786026\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 49 - batch 0 - neg_ELBO = 0.6802122592926025\n",
      " Epoch 49 - batch 50 - neg_ELBO = 0.7799339294433594\n",
      " Epoch 49 - batch 100 - neg_ELBO = 0.6945087313652039\n",
      " Epoch 49 - batch 150 - neg_ELBO = 0.5503252744674683\n",
      "\n",
      "Epoch 49 - Avg loss = 0.7916900590062141\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 50 - batch 0 - neg_ELBO = 0.7526140809059143\n",
      " Epoch 50 - batch 50 - neg_ELBO = 0.7154792547225952\n",
      " Epoch 50 - batch 100 - neg_ELBO = 1.430242896080017\n",
      " Epoch 50 - batch 150 - neg_ELBO = 0.6086610555648804\n",
      "\n",
      "Epoch 50 - Avg loss = 0.7880398619174958\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 51 - batch 0 - neg_ELBO = 0.7808650135993958\n",
      " Epoch 51 - batch 50 - neg_ELBO = 0.6210131049156189\n",
      " Epoch 51 - batch 100 - neg_ELBO = 0.5647004246711731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 51 - batch 150 - neg_ELBO = 0.8635830879211426\n",
      "\n",
      "Epoch 51 - Avg loss = 0.7750945723056794\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 52 - batch 0 - neg_ELBO = 0.7884067296981812\n",
      " Epoch 52 - batch 50 - neg_ELBO = 0.7020179033279419\n",
      " Epoch 52 - batch 100 - neg_ELBO = 0.8674929141998291\n",
      " Epoch 52 - batch 150 - neg_ELBO = 0.7125254273414612\n",
      "\n",
      "Epoch 52 - Avg loss = 0.7790319967269898\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 53 - batch 0 - neg_ELBO = 0.7073894143104553\n",
      " Epoch 53 - batch 50 - neg_ELBO = 0.718885600566864\n",
      " Epoch 53 - batch 100 - neg_ELBO = 0.832739531993866\n",
      " Epoch 53 - batch 150 - neg_ELBO = 0.5579002499580383\n",
      "\n",
      "Epoch 53 - Avg loss = 0.767430075109005\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 54 - batch 0 - neg_ELBO = 0.5914533138275146\n",
      " Epoch 54 - batch 50 - neg_ELBO = 0.5586820840835571\n",
      " Epoch 54 - batch 100 - neg_ELBO = 0.7456687688827515\n",
      " Epoch 54 - batch 150 - neg_ELBO = 1.2126107215881348\n",
      "\n",
      "Epoch 54 - Avg loss = 0.7685497856140137\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 55 - batch 0 - neg_ELBO = 0.6443483233451843\n",
      " Epoch 55 - batch 50 - neg_ELBO = 0.9134349822998047\n",
      " Epoch 55 - batch 100 - neg_ELBO = 0.8971380591392517\n",
      " Epoch 55 - batch 150 - neg_ELBO = 0.6856546998023987\n",
      "\n",
      "Epoch 55 - Avg loss = 0.7611285161972046\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 56 - batch 0 - neg_ELBO = 0.7458679676055908\n",
      " Epoch 56 - batch 50 - neg_ELBO = 0.6522709131240845\n",
      " Epoch 56 - batch 100 - neg_ELBO = 0.8884459733963013\n",
      " Epoch 56 - batch 150 - neg_ELBO = 0.8031554818153381\n",
      "\n",
      "Epoch 56 - Avg loss = 0.7670159667730332\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 57 - batch 0 - neg_ELBO = 0.8210622072219849\n",
      " Epoch 57 - batch 50 - neg_ELBO = 1.1729931831359863\n",
      " Epoch 57 - batch 100 - neg_ELBO = 0.49876856803894043\n",
      " Epoch 57 - batch 150 - neg_ELBO = 0.6966403126716614\n",
      "\n",
      "Epoch 57 - Avg loss = 0.7552893590927124\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 58 - batch 0 - neg_ELBO = 0.7818322777748108\n",
      " Epoch 58 - batch 50 - neg_ELBO = 0.5683274269104004\n",
      " Epoch 58 - batch 100 - neg_ELBO = 0.6458886861801147\n",
      " Epoch 58 - batch 150 - neg_ELBO = 0.7940487861633301\n",
      "\n",
      "Epoch 58 - Avg loss = 0.7355327877402306\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 59 - batch 0 - neg_ELBO = 0.5411460995674133\n",
      " Epoch 59 - batch 50 - neg_ELBO = 0.6562690734863281\n",
      " Epoch 59 - batch 100 - neg_ELBO = 0.6215999126434326\n",
      " Epoch 59 - batch 150 - neg_ELBO = 0.7095595002174377\n",
      "\n",
      "Epoch 59 - Avg loss = 0.7287392354011536\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 60 - batch 0 - neg_ELBO = 1.1887695789337158\n",
      " Epoch 60 - batch 50 - neg_ELBO = 0.7358572483062744\n",
      " Epoch 60 - batch 100 - neg_ELBO = 0.5550522804260254\n",
      " Epoch 60 - batch 150 - neg_ELBO = 0.9067812561988831\n",
      "\n",
      "Epoch 60 - Avg loss = 0.7322016468644142\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 61 - batch 0 - neg_ELBO = 0.7956246733665466\n",
      " Epoch 61 - batch 50 - neg_ELBO = 0.7415313124656677\n",
      " Epoch 61 - batch 100 - neg_ELBO = 0.592644214630127\n",
      " Epoch 61 - batch 150 - neg_ELBO = 0.9479480981826782\n",
      "\n",
      "Epoch 61 - Avg loss = 0.7287783573567868\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 62 - batch 0 - neg_ELBO = 0.9845483899116516\n",
      " Epoch 62 - batch 50 - neg_ELBO = 0.55450439453125\n",
      " Epoch 62 - batch 100 - neg_ELBO = 0.9730282425880432\n",
      " Epoch 62 - batch 150 - neg_ELBO = 0.6357722282409668\n",
      "\n",
      "Epoch 62 - Avg loss = 0.7349511551856994\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 63 - batch 0 - neg_ELBO = 0.7117360234260559\n",
      " Epoch 63 - batch 50 - neg_ELBO = 1.2870045900344849\n",
      " Epoch 63 - batch 100 - neg_ELBO = 0.616463840007782\n",
      " Epoch 63 - batch 150 - neg_ELBO = 0.7543537616729736\n",
      "\n",
      "Epoch 63 - Avg loss = 0.7293261054158211\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 64 - batch 0 - neg_ELBO = 1.1588499546051025\n",
      " Epoch 64 - batch 50 - neg_ELBO = 0.6230945587158203\n",
      " Epoch 64 - batch 100 - neg_ELBO = 0.7776075005531311\n",
      " Epoch 64 - batch 150 - neg_ELBO = 0.6230036020278931\n",
      "\n",
      "Epoch 64 - Avg loss = 0.7261926174163819\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 65 - batch 0 - neg_ELBO = 0.5353594422340393\n",
      " Epoch 65 - batch 50 - neg_ELBO = 0.681479811668396\n",
      " Epoch 65 - batch 100 - neg_ELBO = 0.926330029964447\n",
      " Epoch 65 - batch 150 - neg_ELBO = 0.7662071585655212\n",
      "\n",
      "Epoch 65 - Avg loss = 0.7117947667837143\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 66 - batch 0 - neg_ELBO = 0.672299861907959\n",
      " Epoch 66 - batch 50 - neg_ELBO = 0.587001383304596\n",
      " Epoch 66 - batch 100 - neg_ELBO = 0.6603370308876038\n",
      " Epoch 66 - batch 150 - neg_ELBO = 0.7866115570068359\n",
      "\n",
      "Epoch 66 - Avg loss = 0.7125646692514419\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 67 - batch 0 - neg_ELBO = 0.5459652543067932\n",
      " Epoch 67 - batch 50 - neg_ELBO = 0.5855177044868469\n",
      " Epoch 67 - batch 100 - neg_ELBO = 0.8136364221572876\n",
      " Epoch 67 - batch 150 - neg_ELBO = 0.6947178244590759\n",
      "\n",
      "Epoch 67 - Avg loss = 0.6980427527427673\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 68 - batch 0 - neg_ELBO = 1.459052324295044\n",
      " Epoch 68 - batch 50 - neg_ELBO = 1.2280136346817017\n",
      " Epoch 68 - batch 100 - neg_ELBO = 0.46151378750801086\n",
      " Epoch 68 - batch 150 - neg_ELBO = 0.6290028095245361\n",
      "\n",
      "Epoch 68 - Avg loss = 0.6936314149200916\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 69 - batch 0 - neg_ELBO = 0.6735394597053528\n",
      " Epoch 69 - batch 50 - neg_ELBO = 0.6846144795417786\n",
      " Epoch 69 - batch 100 - neg_ELBO = 0.7326530814170837\n",
      " Epoch 69 - batch 150 - neg_ELBO = 0.6779680848121643\n",
      "\n",
      "Epoch 69 - Avg loss = 0.6935707405209541\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 70 - batch 0 - neg_ELBO = 0.6538503766059875\n",
      " Epoch 70 - batch 50 - neg_ELBO = 0.656169593334198\n",
      " Epoch 70 - batch 100 - neg_ELBO = 0.565493106842041\n",
      " Epoch 70 - batch 150 - neg_ELBO = 0.7765514850616455\n",
      "\n",
      "Epoch 70 - Avg loss = 0.6922225996851921\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 71 - batch 0 - neg_ELBO = 0.8648374080657959\n",
      " Epoch 71 - batch 50 - neg_ELBO = 0.5579363703727722\n",
      " Epoch 71 - batch 100 - neg_ELBO = 0.7799996137619019\n",
      " Epoch 71 - batch 150 - neg_ELBO = 0.663948655128479\n",
      "\n",
      "Epoch 71 - Avg loss = 0.6909457355737686\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 72 - batch 0 - neg_ELBO = 0.6903839111328125\n",
      " Epoch 72 - batch 50 - neg_ELBO = 0.6387093663215637\n",
      " Epoch 72 - batch 100 - neg_ELBO = 0.6918819546699524\n",
      " Epoch 72 - batch 150 - neg_ELBO = 1.0838847160339355\n",
      "\n",
      "Epoch 72 - Avg loss = 0.6793242351710796\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 73 - batch 0 - neg_ELBO = 0.6205366253852844\n",
      " Epoch 73 - batch 50 - neg_ELBO = 0.6069746017456055\n",
      " Epoch 73 - batch 100 - neg_ELBO = 0.6720425486564636\n",
      " Epoch 73 - batch 150 - neg_ELBO = 0.607125461101532\n",
      "\n",
      "Epoch 73 - Avg loss = 0.6848348173499107\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 74 - batch 0 - neg_ELBO = 0.5290648937225342\n",
      " Epoch 74 - batch 50 - neg_ELBO = 1.274064064025879\n",
      " Epoch 74 - batch 100 - neg_ELBO = 0.5755912065505981\n",
      " Epoch 74 - batch 150 - neg_ELBO = 0.5613288283348083\n",
      "\n",
      "Epoch 74 - Avg loss = 0.6830885805189609\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 75 - batch 0 - neg_ELBO = 0.813530445098877\n",
      " Epoch 75 - batch 50 - neg_ELBO = 0.5767843127250671\n",
      " Epoch 75 - batch 100 - neg_ELBO = 0.5682594180107117\n",
      " Epoch 75 - batch 150 - neg_ELBO = 0.5169811248779297\n",
      "\n",
      "Epoch 75 - Avg loss = 0.681365784406662\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 76 - batch 0 - neg_ELBO = 0.7246990203857422\n",
      " Epoch 76 - batch 50 - neg_ELBO = 0.6307793855667114\n",
      " Epoch 76 - batch 100 - neg_ELBO = 0.7600658535957336\n",
      " Epoch 76 - batch 150 - neg_ELBO = 0.49946773052215576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76 - Avg loss = 0.6805380128324032\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 77 - batch 0 - neg_ELBO = 1.0740811824798584\n",
      " Epoch 77 - batch 50 - neg_ELBO = 0.5371919274330139\n",
      " Epoch 77 - batch 100 - neg_ELBO = 0.6009485125541687\n",
      " Epoch 77 - batch 150 - neg_ELBO = 0.5125572681427002\n",
      "\n",
      "Epoch 77 - Avg loss = 0.6686445070803165\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 78 - batch 0 - neg_ELBO = 0.7537063360214233\n",
      " Epoch 78 - batch 50 - neg_ELBO = 1.0419402122497559\n",
      " Epoch 78 - batch 100 - neg_ELBO = 0.6730476021766663\n",
      " Epoch 78 - batch 150 - neg_ELBO = 0.7009143233299255\n",
      "\n",
      "Epoch 78 - Avg loss = 0.6829746857285499\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 79 - batch 0 - neg_ELBO = 0.5128962993621826\n",
      " Epoch 79 - batch 50 - neg_ELBO = 0.909134030342102\n",
      " Epoch 79 - batch 100 - neg_ELBO = 0.5785324573516846\n",
      " Epoch 79 - batch 150 - neg_ELBO = 0.6191568970680237\n",
      "\n",
      "Epoch 79 - Avg loss = 0.685738241225481\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 80 - batch 0 - neg_ELBO = 0.6888808012008667\n",
      " Epoch 80 - batch 50 - neg_ELBO = 0.5376719236373901\n",
      " Epoch 80 - batch 100 - neg_ELBO = 0.6093758344650269\n",
      " Epoch 80 - batch 150 - neg_ELBO = 0.5496334433555603\n",
      "\n",
      "Epoch 80 - Avg loss = 0.6633611802756786\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 81 - batch 0 - neg_ELBO = 0.7065660953521729\n",
      " Epoch 81 - batch 50 - neg_ELBO = 0.6769417524337769\n",
      " Epoch 81 - batch 100 - neg_ELBO = 0.5755921006202698\n",
      " Epoch 81 - batch 150 - neg_ELBO = 0.6495593190193176\n",
      "\n",
      "Epoch 81 - Avg loss = 0.6696862010657787\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 82 - batch 0 - neg_ELBO = 0.6747167110443115\n",
      " Epoch 82 - batch 50 - neg_ELBO = 0.6037469506263733\n",
      " Epoch 82 - batch 100 - neg_ELBO = 0.5150489211082458\n",
      " Epoch 82 - batch 150 - neg_ELBO = 0.5136513113975525\n",
      "\n",
      "Epoch 82 - Avg loss = 0.6562787608802318\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 83 - batch 0 - neg_ELBO = 0.6312075257301331\n",
      " Epoch 83 - batch 50 - neg_ELBO = 0.6736368536949158\n",
      " Epoch 83 - batch 100 - neg_ELBO = 1.232033610343933\n",
      " Epoch 83 - batch 150 - neg_ELBO = 0.6822988986968994\n",
      "\n",
      "Epoch 83 - Avg loss = 0.6680976949632168\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 84 - batch 0 - neg_ELBO = 0.7296158671379089\n",
      " Epoch 84 - batch 50 - neg_ELBO = 1.0938289165496826\n",
      " Epoch 84 - batch 100 - neg_ELBO = 0.7713323831558228\n",
      " Epoch 84 - batch 150 - neg_ELBO = 0.9192911982536316\n",
      "\n",
      "Epoch 84 - Avg loss = 0.6724778780341149\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 85 - batch 0 - neg_ELBO = 0.5885382890701294\n",
      " Epoch 85 - batch 50 - neg_ELBO = 0.5518290996551514\n",
      " Epoch 85 - batch 100 - neg_ELBO = 0.6034374833106995\n",
      " Epoch 85 - batch 150 - neg_ELBO = 0.7281989455223083\n",
      "\n",
      "Epoch 85 - Avg loss = 0.6566725960373878\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 86 - batch 0 - neg_ELBO = 0.7192842960357666\n",
      " Epoch 86 - batch 50 - neg_ELBO = 0.667556881904602\n",
      " Epoch 86 - batch 100 - neg_ELBO = 0.6872947216033936\n",
      " Epoch 86 - batch 150 - neg_ELBO = 0.7236428260803223\n",
      "\n",
      "Epoch 86 - Avg loss = 0.6526905252039432\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 87 - batch 0 - neg_ELBO = 0.6651437282562256\n",
      " Epoch 87 - batch 50 - neg_ELBO = 0.49749425053596497\n",
      " Epoch 87 - batch 100 - neg_ELBO = 0.5684627890586853\n",
      " Epoch 87 - batch 150 - neg_ELBO = 0.6221422553062439\n",
      "\n",
      "Epoch 87 - Avg loss = 0.6581759330630302\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 88 - batch 0 - neg_ELBO = 0.590404748916626\n",
      " Epoch 88 - batch 50 - neg_ELBO = 0.6168738007545471\n",
      " Epoch 88 - batch 100 - neg_ELBO = 0.6566839814186096\n",
      " Epoch 88 - batch 150 - neg_ELBO = 0.7966250777244568\n",
      "\n",
      "Epoch 88 - Avg loss = 0.6567454032599926\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 89 - batch 0 - neg_ELBO = 0.5497717261314392\n",
      " Epoch 89 - batch 50 - neg_ELBO = 0.5466567277908325\n",
      " Epoch 89 - batch 100 - neg_ELBO = 0.6835756897926331\n",
      " Epoch 89 - batch 150 - neg_ELBO = 0.6703149080276489\n",
      "\n",
      "Epoch 89 - Avg loss = 0.6481124876439571\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 90 - batch 0 - neg_ELBO = 0.5604989528656006\n",
      " Epoch 90 - batch 50 - neg_ELBO = 0.5160397291183472\n",
      " Epoch 90 - batch 100 - neg_ELBO = 0.5064153075218201\n",
      " Epoch 90 - batch 150 - neg_ELBO = 0.6964641213417053\n",
      "\n",
      "Epoch 90 - Avg loss = 0.6421184228360652\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 91 - batch 0 - neg_ELBO = 0.49136674404144287\n",
      " Epoch 91 - batch 50 - neg_ELBO = 0.5803868174552917\n",
      " Epoch 91 - batch 100 - neg_ELBO = 0.5837191939353943\n",
      " Epoch 91 - batch 150 - neg_ELBO = 0.530458927154541\n",
      "\n",
      "Epoch 91 - Avg loss = 0.6552509723603726\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 92 - batch 0 - neg_ELBO = 0.7844956517219543\n",
      " Epoch 92 - batch 50 - neg_ELBO = 0.7941771149635315\n",
      " Epoch 92 - batch 100 - neg_ELBO = 1.1133421659469604\n",
      " Epoch 92 - batch 150 - neg_ELBO = 0.6179746985435486\n",
      "\n",
      "Epoch 92 - Avg loss = 0.6409207437932491\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 93 - batch 0 - neg_ELBO = 0.6314288377761841\n",
      " Epoch 93 - batch 50 - neg_ELBO = 0.5072986483573914\n",
      " Epoch 93 - batch 100 - neg_ELBO = 0.6149572134017944\n",
      " Epoch 93 - batch 150 - neg_ELBO = 0.5921139121055603\n",
      "\n",
      "Epoch 93 - Avg loss = 0.6410171450674533\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 94 - batch 0 - neg_ELBO = 0.6332390308380127\n",
      " Epoch 94 - batch 50 - neg_ELBO = 0.6289962530136108\n",
      " Epoch 94 - batch 100 - neg_ELBO = 0.44616493582725525\n",
      " Epoch 94 - batch 150 - neg_ELBO = 0.49051633477211\n",
      "\n",
      "Epoch 94 - Avg loss = 0.6491530001163482\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 95 - batch 0 - neg_ELBO = 0.4935601055622101\n",
      " Epoch 95 - batch 50 - neg_ELBO = 0.9202412962913513\n",
      " Epoch 95 - batch 100 - neg_ELBO = 0.5572217106819153\n",
      " Epoch 95 - batch 150 - neg_ELBO = 0.7040287852287292\n",
      "\n",
      "Epoch 95 - Avg loss = 0.635203074067831\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 96 - batch 0 - neg_ELBO = 0.47095489501953125\n",
      " Epoch 96 - batch 50 - neg_ELBO = 0.6157544851303101\n",
      " Epoch 96 - batch 100 - neg_ELBO = 0.5450024008750916\n",
      " Epoch 96 - batch 150 - neg_ELBO = 0.6023937463760376\n",
      "\n",
      "Epoch 96 - Avg loss = 0.637061043381691\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 97 - batch 0 - neg_ELBO = 0.6319969892501831\n",
      " Epoch 97 - batch 50 - neg_ELBO = 0.6248175501823425\n",
      " Epoch 97 - batch 100 - neg_ELBO = 0.5365779995918274\n",
      " Epoch 97 - batch 150 - neg_ELBO = 0.5349586009979248\n",
      "\n",
      "Epoch 97 - Avg loss = 0.6392904233932495\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 98 - batch 0 - neg_ELBO = 0.44799596071243286\n",
      " Epoch 98 - batch 50 - neg_ELBO = 0.5121454000473022\n",
      " Epoch 98 - batch 100 - neg_ELBO = 0.5818635821342468\n",
      " Epoch 98 - batch 150 - neg_ELBO = 0.7371808886528015\n",
      "\n",
      "Epoch 98 - Avg loss = 0.6332009424269199\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 99 - batch 0 - neg_ELBO = 0.6690675616264343\n",
      " Epoch 99 - batch 50 - neg_ELBO = 0.9787539839744568\n",
      " Epoch 99 - batch 100 - neg_ELBO = 0.5581848621368408\n",
      " Epoch 99 - batch 150 - neg_ELBO = 0.427236407995224\n",
      "\n",
      "Epoch 99 - Avg loss = 0.6430164666473865\n",
      "\n",
      "----------------------------------------------------------------------\n",
      " Epoch 100 - batch 0 - neg_ELBO = 0.4960888624191284\n",
      " Epoch 100 - batch 50 - neg_ELBO = 0.6001294255256653\n",
      " Epoch 100 - batch 100 - neg_ELBO = 0.6092811226844788\n",
      " Epoch 100 - batch 150 - neg_ELBO = 0.4578058421611786\n",
      "\n",
      "Epoch 100 - Avg loss = 0.6364691604673862\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "history=vae.fit(data_train, epochs=100, batch_size=1)\n",
    "p_x = vae.reconstructed_probability(data_train)\n",
    "np.save('P_x', p_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "flush-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_size = 8\n",
    "# encoders_sizes = np.linspace(data_train.shape[1], latent_size, 7).astype('int')[1:-1]\n",
    "# with VAE((data_train.shape[1],), encode_sizes=encoders_sizes, latent_size=latent_size, lr=0.00001) as vae:\n",
    "#         vae.fit(data_train, epochs=200, batch_size=256)\n",
    "#         p_x = vae.reconstructed_probability(data_train)\n",
    "# np.save('P_x', p_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "liberal-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE.fit(acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "normal-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(history.acc_loss['Avg loss'],label=\"Training  Loss\")\n",
    "# #plt.plot(history.history[\"val_loss\"],label=\"Validation Loss\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "overhead-things",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders_sizes.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "tired-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "heavy-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "px=p_x.reshape(200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "pretty-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "executive-spanish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "referenced-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=vae.is_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "intended-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "stock-canberra",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'is_outlier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-8329bd1cfad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_outlier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_outlier'"
     ]
    }
   ],
   "source": [
    "test_pred=history.is_outlier(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-popularity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
